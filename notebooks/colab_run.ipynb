{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LunarLander Actor-Critic in Google Colab\n",
        "This notebook shows how to clone the repo, install dependencies, train the agent, and evaluate itâ€”all from within Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove existing directory if it exists and clone fresh\n",
        "%cd /content\n",
        "!rm -rf lunar-lander-rl\n",
        "!git clone https://github.com/NudelMaster/lunar-lander-rl.git\n",
        "%cd lunar-lander-rl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Install system packages (Box2D, display) and Python dependencies\n",
        "\n",
        "Run these only in Colab. If you run locally, skip the `apt-get` lines and just do `pip install -r requirements.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "apt-get -qq install xvfb x11-utils &> /dev/null\n",
        "pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) (Optional) Create a virtual display for Gym rendering\n",
        "\n",
        "This ensures `env.render(\"rgb_array\")` works headlessly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "disp = Display(visible=0, size=(1400, 900))\n",
        "disp.start()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train the Agent\n",
        "\n",
        "This cell imports the `Agent` class and kicks off training for up to `NUM_ITER` episodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' \n",
        "Create an Agent instance and start training it.\n",
        "\n",
        "You can adjust the training parameters:\n",
        "- num_iter: number of training iterations (episodes).\n",
        "- score_to_solve: the target score that defines when training is considered successful.\n",
        "- resume: set to True to continue training from a saved checkpoint, False to start fresh.\n",
        "\n",
        "Feel free to modify these parameters to train for more or fewer episodes,\n",
        "or to change the success criteria as needed.\n",
        "'''\n",
        "from agent import Agent\n",
        "from config import NUM_ITER, SCORE_TO_SOLVE\n",
        "\n",
        "agent = Agent()\n",
        "agent.train(num_iter=NUM_ITER, score_to_solve=SCORE_TO_SOLVE, resume=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Evaluate the Trained Agent\n",
        "\n",
        "After training finishes (or early-stops), a file `lunar_lander_actor_critic.pth` will exist.  \n",
        "We now evaluate it and show a GIF.  \n",
        "The GIF will be saved as `lunar_lander_final.gif` in this folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clip = agent.evaluate(model_path=\"lunar_lander_actor_critic.pth\", greedy=True)\n",
        "agent.animate(clip)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
